---
title: "Function-Based Behavior Intervention Plans: A Practical Guide"
excerpt: "Go beyond the basics of BIP writing. Learn how to use IISCA, Skill-Based Treatment, competition analysis, and implementation fidelity strategies to build BIPs that actually work in school settings."
date: "2026-02-01T09:00:00.000Z"
author: Rob Spain
featured_image: null
tags:
  - BIP
  - Behavior Intervention Plan
  - FBA
  - School-Based ABA
  - Skill-Based Treatment
  - IISCA
  - blog
status: published
meta_title: "Function-Based BIPs: Beyond the Basics | BehaviorSchool"
meta_description: "Advanced guide to function-based BIPs in schools. IISCA, Skill-Based Treatment, competition analysis, and implementation tips."
---

*AI-assisted draft; reviewed and edited by Rob Spain.*

If you went to grad school for behavior analysis, you learned the four functions of behavior. Escape, attention, access, automatic. You learned to do an FBA, identify the function, pick a replacement behavior that serves the same function, and write it all up. Cool. That is the floor, not the ceiling.

Most BIPs fail. Not because the science is wrong, but because the plan was too simple for the problem. Behavior in schools is messy, multiply controlled, and embedded in a context where 30 other students, a stressed teacher, and an unpredictable schedule are all part of the equation. A plan that says "teach the student to request a break" without addressing why the break card sits untouched on the desk every single day is not a function-based plan. It is a gesture toward one.

This guide is for practitioners who want to build BIPs that actually hold up in real classrooms with real kids and real staff. I write this as someone who does it every day in a public school district, and I am going to share what I have learned works, what does not, and what the research supports when we move past the textbook basics.

## Start with a Real Functional Analysis, Not Just an FBA

Here is something that bothers me: we tell people to "conduct an FBA first" as if that is a single, clear thing. In practice, most school FBAs are indirect assessments (interviews, rating scales) plus some ABC data. That is a hypothesis at best. It is not confirmation.

If you want a BIP that actually works, you need to test your hypothesis. In schools, that means a practical functional analysis.

### The IISCA in Schools

The Interview-Informed Synthesized Contingency Analysis (Hanley, Jin, Vanselow, & Hanratty, 2014) is the most school-friendly FA model I have used. Here is why: instead of testing isolated conditions one at a time (which takes forever and often does not match real-world conditions), the IISCA uses interview data to create a single test condition that combines the relevant variables.

Here is how I run one in a school setting:

**Step 1: The open-ended interview.** I sit down with the teacher, the para, and anyone else who sees the behavior daily. I use Hanley's open-ended functional assessment interview (it is freely available). The goal is to identify what the synthesized reinforcer looks like for this specific student.

**Step 2: Build the test and control conditions.** Based on the interview, I create a test condition that includes all the relevant establishing operations at once, and a control condition where everything the student wants is freely available.

**Step 3: Run it.** I alternate between test and control in brief sessions, usually 5 minutes each. For a student like Marcus, a 4th grader who flips desks during writing, the test condition might look like: I present a writing demand, withdraw attention, and remove access to his drawing materials simultaneously. The control condition: no demands, my full attention, drawing materials available. If desk-flipping happens reliably in the test and not the control, I have confirmed the function.

The whole thing takes 30 to 60 minutes across a morning. Compare that to weeks of inconclusive ABC data.

### Why Synthesized Contingencies Matter

Here is what the standard four-function model misses: most challenging behavior in schools is multiply controlled. Marcus is not just escaping writing. He is escaping writing AND losing access to drawing AND losing adult attention all at the same time. If I write a BIP that only addresses escape, I am addressing one-third of the problem.

Hanley's work (2012) showed that when you test synthesized conditions, where multiple variables operate together, you get clearer differentiation and more useful results than single-function analyses. In my experience, this is almost always the case with the students who end up needing BIPs. The easy, single-function cases often resolve with simple classroom adjustments. The kids who land on my caseload have complex, multiply controlled behavior.

Your BIP needs to address the full reinforcer package, not just one piece of it.

## Skill-Based Treatment: The Framework That Changed How I Write BIPs

If you are not familiar with Greg Hanley's Practical Functional Assessment and Skill-Based Treatment (PFA/SBT) model, stop and go read about it. It has fundamentally changed how I approach intervention planning.

SBT is not just "teach a replacement behavior." It is a structured progression with three integrated components:

### 1. Functional Communication Training (FCT)

Teach the student to request the entire reinforcer package using a functional communication response (FCR). For Marcus, that is not just "request a break." It is "request a break from writing with access to drawing and adult interaction." The FCR has to access everything the problem behavior was accessing.

I start by reinforcing the FCR on a dense schedule, every single time. The student learns: this new response works perfectly, instantly, every time.

### 2. Tolerance Training

Here is where most BIPs stop, and where SBT keeps going. Once the FCR is strong, I begin systematically introducing delays and denials. "I hear you, Marcus. You want a break. We can take one in two minutes." Then three minutes. Then five.

This is not arbitrary. I am building tolerance for the conditions that used to evoke problem behavior. I am doing it gradually, with signals, and with the student's buy-in. Critical: I always follow through. If I say "in two minutes," it happens in two minutes. Trust is the foundation.

### 3. Contextually Appropriate Behavior (CAB)

This is the piece that makes SBT actually sustainable. During those delay periods, I teach the student what TO do. For Marcus, that might be: continue writing for two more sentences, use a self-monitoring checklist, or work on a modified version of the task. The student learns to tolerate the delay by engaging in appropriate behavior, and that appropriate behavior itself gets reinforced.

The progression looks like this: FCR (100% reinforced) then tolerate brief delays then engage in CAB during delays then gradually extend expectations.

This is not a quick fix. It takes weeks. But the outcomes are durable because you are building actual skills, not just managing contingencies.

## Competition Analysis: Will Your Replacement Behavior Actually Win?

Before I finalize any BIP, I do a competition analysis. This is the question most BIP writers skip: can the replacement behavior actually compete with the problem behavior?

Think about it from the student's perspective. Problem behavior has been working for months or years. It is practiced, efficient, and reliably reinforced (even if intermittently). Your shiny new replacement behavior is unfamiliar, untested, and requires the student to trust that adults will follow through.

I evaluate four dimensions:

**Effort.** Is the replacement behavior equal to or easier than the problem behavior? If flipping a desk gets Marcus out of writing instantly, but the break card requires him to find the card, hand it to the teacher, and wait for acknowledgment, the problem behavior wins on effort. Solution: make the FCR as easy as possible. A single word, a gesture, a tap on a visual.

**Latency to reinforcement.** How fast does the student get what they need? If screaming gets immediate teacher response but raising a hand means waiting three minutes, screaming wins. Solution: at the start of intervention, reinforce the FCR faster than the problem behavior ever got reinforced.

**Quality of reinforcement.** Does the replacement get the student something as good as what the problem behavior got them? If throwing a chair results in being sent to a quiet office (full escape plus preferred environment) but the break card gets a two-minute break at a desk in the same noisy classroom, the problem behavior wins on quality. Solution: match the reinforcer quality, then fade.

**Consistency.** Does the replacement work every single time? If the break card works with the morning teacher but the afternoon teacher says "not right now," the student learns that the replacement is unreliable. Problem behavior, which has always worked with everyone, wins. Solution: train every implementer to honor the FCR 100% of the time at the start.

If your replacement behavior cannot beat the problem behavior on at least effort and consistency, your BIP will fail. Full stop. Adjust before you implement.

## Setting Events and Motivating Operations: Go Deeper

Most BIPs address setting events with something like "conduct a morning check-in." That is fine as far as it goes, but it does not go far enough.

Setting events and motivating operations (MOs) are the reason the same student can be fine on Tuesday and in crisis on Wednesday. If you are not assessing and responding to these variables, you are writing a plan for an average day that does not exist.

Here is what I actually assess:

**Sleep.** I ask caregivers to track sleep patterns. A student running on four hours of sleep has a fundamentally different threshold for frustration. For Amara, a 6th grader on my caseload, we discovered that every major incident occurred after a night with less than six hours of sleep. That information changed the entire antecedent plan for those days.

**Medication changes.** Dose adjustments, missed doses, new medications, all of these alter the behavioral picture. I am not making medical decisions, but I need to know when these changes happen so I can interpret data accurately.

**Family stressors.** Custody transitions, housing instability, food insecurity, parental conflict. I am not a therapist and this is not my lane to treat, but a student who spent the morning watching their parents argue has a different set of establishing operations than the same student on a calm day.

**Sensory needs.** Not the generic "provide fidgets" kind. Actual sensory assessment data. Is the fluorescent lighting in third period a consistent antecedent? Is the noise level in the cafeteria functionally aversive? These are abolishing operations if addressed and establishing operations if ignored.

**Build conditional pathways into the BIP.** Instead of one static plan, I write plans with if-then branches: "If the morning check-in indicates poor sleep or high stress, implement the modified schedule (reduced demands, increased reinforcer access, proactive sensory breaks) for the first two hours."

## ACT-Informed Strategies for Older Students

For middle and high school students, pure contingency management often is not enough and can feel controlling or infantilizing. This is where Acceptance and Commitment Therapy (ACT) informed components earn their place in a BIP.

I am not doing therapy. I am a BCBA. But ACT is rooted in behavior analysis (relational frame theory), and several components translate directly into BIP strategies:

**Defusion.** Teaching a student to notice a thought without being controlled by it. For Jaylen, a 10th grader who shuts down when he thinks "I am stupid," I taught him to say "I am having the thought that I am stupid" and then re-engage with the task. This is a skill you can operationally define, teach, and measure.

**Acceptance.** Teaching tolerance for discomfort without avoidance. This aligns directly with the tolerance training component of SBT but frames it in language that resonates with adolescents. "You can feel frustrated and still do the next step" is more effective with a 16-year-old than a token board.

**Values.** Connecting behavioral expectations to what the student actually cares about. Jaylen wants to graduate and work in music production. When we linked assignment completion to "building the discipline you will need in a studio," his motivation shifted from external contingencies to something internal. That is not magic; that is augmental control.

For students with the verbal repertoire to engage with these concepts, ACT-informed components make the BIP more dignified, more durable, and more likely to generalize beyond the school setting.

## Implementation Fidelity: Why Good BIPs Fail

I will say it plainly: implementation fidelity is the number one reason BIPs fail in schools. Not bad assessment, not wrong function, not poor strategy selection. Staff do not implement the plan as written. And honestly, it is usually our fault for writing plans that are unrealistic, unclear, or unsupported.

Here is what I do to address this:

**Train, do not just distribute.** Handing a teacher a 12-page BIP and saying "let me know if you have questions" is not training. I do a 20-minute walkthrough with every implementer. We role-play the replacement behavior, practice the reinforcement procedure, and rehearse the response to problem behavior. I demonstrate, they practice, I give feedback.

**Self-monitoring checklists.** I give staff a simple daily checklist: Did I prompt the FCR before demands? Did I reinforce the FCR within 5 seconds? Did I avoid providing the functional reinforcer after problem behavior? Three to five items, yes/no, takes 30 seconds at the end of the period. This is not surveillance. It is a self-management tool that keeps the plan active in working memory.

**Coaching, not just consultation.** I observe implementation at least weekly for the first month. Not to evaluate, but to coach. I provide immediate, specific, positive feedback ("You caught his FCR and responded in two seconds, that was perfect") and gentle correction ("Next time he raises the card, try to respond before redirecting the other student").

**Simplify ruthlessly.** If the plan requires more than three to four distinct staff behaviors, it is too complex. I would rather have three strategies implemented with fidelity than eight strategies implemented inconsistently. Cut the plan down to what matters most and add complexity only after the basics are solid.

**Measure fidelity directly.** I use a simple fidelity checklist during my observations. If fidelity drops below 80%, I do not blame the staff. I simplify the plan or increase support. The data tells you whether you have an intervention problem or an implementation problem.

## Generalization: Build It In From Day One

Generalization is not a phase that comes after the behavior improves. It is a design feature of the plan from the start.

Here is what this looks like in practice:

**Train with multiple exemplars.** If Marcus learns to use his FCR with me, it will not automatically transfer to his teacher, the lunch aide, or the substitute. I train the FCR with at least three different adults in the first week.

**Train across settings.** The FCR that works in the resource room needs to work in the general education classroom, the cafeteria, and specials. I practice it in each setting, with the adults in that setting, during the actual routines.

**Program common stimuli.** I make sure the visual supports, cue cards, or whatever tools the student uses look the same everywhere. If the break card is green in my room and does not exist in science class, generalization will not happen.

**Fade to natural contingencies.** The goal is not for the student to use a break card forever. The goal is for the student to develop internal regulation skills that work without external supports. I plan the fading sequence from the beginning and share it with the team so everyone knows where we are headed.

**Teach self-management early.** Even with young students, I build in self-monitoring as soon as the replacement behavior is established. A simple "Did I use my words?" self-check after each activity period teaches the student to manage their own behavior rather than relying on adult prompts indefinitely.

## When the FBA Is Wrong: How to Pivot

Sometimes the data does not match the hypothesis. You implemented the BIP with good fidelity for four weeks and the problem behavior has not changed, or it has gotten worse. This is not failure. This is information.

Here is my decision tree:

**Step 1: Check fidelity first.** Nine times out of ten, the issue is implementation, not assessment. Review your fidelity data. If staff are implementing below 80%, fix that before changing anything else.

**Step 2: Check the reinforcer.** Is the FCR actually accessing the functional reinforcer? I had a student, Deshawn, whose BIP was built around escape from writing. The plan gave him breaks, but his behavior did not improve. When I looked more closely, I realized the breaks were happening at his desk in the same room, still surrounded by the aversive stimuli. He needed to physically leave the space. The function was right, but the reinforcer quality was wrong.

**Step 3: Reassess the function.** If fidelity is good and the reinforcer is matched, your hypothesis may be wrong. Go back and run a functional analysis. Do not just review the indirect data again. Actually test the conditions. I have had cases where the interview data pointed to escape but the FA revealed automatic reinforcement. The topography looked the same, but the function was completely different.

**Step 4: Look for multiply controlled behavior.** If you tested single functions initially, try synthesized conditions. The IISCA approach often reveals maintaining variables that isolated condition FAs miss.

**Step 5: Consider the setting events.** Maybe the function is right but the BIP does not account for the conditions under which the behavior is most likely. Add conditional pathways based on MO assessment.

**Step 6: Talk to the student.** For students with sufficient verbal skills, ask them. Not "why do you do this?" which invites post-hoc rationalization, but "what would make this class better for you?" or "what is the hardest part of your day?" Students often have insight that our data does not capture.

The willingness to say "my hypothesis was wrong" and go back to assessment is what separates competent practitioners from those who blame the student when the plan does not work.

## Putting It All Together

A function-based BIP that works in a real school is not a form you fill out. It is a living system that includes:

- A confirmed functional hypothesis (ideally FA-confirmed, not just interview-based)
- Intervention strategies that address the full reinforcer package (synthesized contingencies)
- A skill-building progression (FCT, tolerance training, CAB) not just a replacement behavior
- A competition analysis showing the replacement can actually win
- Conditional pathways for setting events and MOs
- A realistic implementation plan with fidelity monitoring
- Generalization programming built in from day one
- Decision rules for when and how to pivot

This is more work upfront. Significantly more. But it saves time in the long run because you are not rewriting the BIP every six weeks when the generic plan fails again.

BehaviorSchool's [FBA-to-BIP Generator](/fba-to-bip) can help you draft the initial framework, including function-matched strategies, replacement behavior teaching plans, and data collection systems. Use it as a starting point, then layer in the advanced components: your competition analysis, your SBT progression, your fidelity monitoring plan. Pair it with the [IEP Goal Writer](/iep-goal-writer) to align your BIP goals with measurable IEP objectives.

The science of behavior works. The challenge has always been implementing it well, consistently, in messy, underfunded, overcrowded schools. That is our job. Let us do it well.

## Frequently Asked Questions About Function-Based BIPs

### What is the difference between a traditional FBA and the IISCA approach?

A traditional FBA typically relies on indirect assessment (interviews, rating scales) and descriptive assessment (ABC data) to hypothesize a function. The IISCA goes further by using interview data to create a synthesized test condition that combines all relevant variables, then directly tests whether behavior occurs under those conditions versus a control. It is faster, more school-friendly, and often more accurate than traditional single-function experimental analyses.

### Can a behavior have more than one function?

Absolutely, and in my experience, the students who need BIPs almost always have multiply controlled behavior. This is exactly why the IISCA and synthesized contingency approach is so valuable. Your BIP must address the full reinforcer package, not just one function in isolation.

### What is Skill-Based Treatment and how is it different from just teaching a replacement behavior?

SBT (Hanley, 2012; Hanley et al., 2014) is a structured three-phase approach: functional communication training (to request the full reinforcer), tolerance training (to handle delays and denials), and contextually appropriate behavior training (to engage in expected behavior during those delays). Traditional BIPs often stop at FCT. SBT builds the complete skill set needed for long-term success.

### How do I know if my replacement behavior can compete with the problem behavior?

Run a competition analysis. Evaluate the replacement behavior against the problem behavior on four dimensions: effort (is it as easy or easier?), latency to reinforcement (is it as fast or faster?), quality of reinforcement (does it access an equivalent reinforcer?), and consistency (does it work every time?). If the replacement loses on more than one dimension, redesign before implementing.

### What should I do when a BIP is not working after several weeks?

Follow this sequence: first check implementation fidelity, then verify the reinforcer match, then reassess the function with a direct analysis (not just more interviews), then look for multiply controlled behavior, then examine setting events and MOs. Do not blame the student or simply add more punishment-based strategies.

### How do I get teachers to actually implement the BIP?

Train them directly with modeling and rehearsal, give them a simple self-monitoring checklist, provide weekly coaching with specific positive feedback, and keep the plan simple. Three strategies implemented well beats eight strategies implemented poorly. If fidelity is low, simplify the plan before blaming the implementer.

### Is Skill-Based Treatment appropriate for all age groups?

The core framework applies across ages, but the specific strategies look different. For younger students, the emphasis is on FCT and structured tolerance training with visual supports. For older students, you can integrate ACT-informed components like defusion and values-based motivation alongside the SBT framework. The principles are the same; the delivery adapts to developmental level.

**Ready to build better BIPs?** [Try the BehaviorSchool FBA-to-BIP Generator](/fba-to-bip) to get a function-based draft in minutes, then customize with the advanced strategies outlined above.

---

*Want more practical guides for school-based behavior support? [Subscribe to the BehaviorSchool newsletter](/subscribe) for weekly tips, templates, and strategies.*
